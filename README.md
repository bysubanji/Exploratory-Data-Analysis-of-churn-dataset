

<h1 align="center"> Telecom Churn Analysis
 </h1>

<h3 align="center"> AlmaBetter Verfied Project - <a href="https://www.almabetter.com/"> AlmaBetter School </a> </h5>

![telcom](https://user-images.githubusercontent.com/95616692/167258167-901f3de8-0bd5-46ea-ada1-d04ecf985cac.png)


<p> </p>

![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

<h2> :floppy_disk: Table of Content</h2>

  * [Introduction](#Introduction)
  * [Abstract](#Abstract)
  * [Dataset Information](#dataset-information)
  * [Problem Statement](#Problem-Statement)
  * [Conclusion](#Conclusion)


![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)


<h2> :book: Introduction:</h2>

* In the telecommunication industry, the main profit comes from the service provided to customers with their plans and features.

* This EDA will use Python libraries, matplotlib, and Seaborn to examine the Telecom dataset through visualizations and graphs. 

* Orange SA telecommunication dataset contains Area Code and International Plan.

* If a consumer unsubscribes a membership with one company and becomes a customer of another company, this customer is known as a Churn customer.

* Our major goal in this project is to identify reasons for customer chrun by doing analysis features such as the plans, which in our case is a brief summary description of the customer plans.


![image](https://user-images.githubusercontent.com/95616692/167260084-61a6c20c-fe81-45c4-8f8d-f668f18a4b4e.png)



![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)


<h2> :book: Abstract:</h2>

* The objective was to anticipate bunches of comparable substance by matching text-based elements.

* Exploratory Data Analysis is done on the dataset to get the insights from the information however the principal invalid qualities are taken care of. Likewise, some hypothesis testing was additionally performed from the experiences from EDA.

* After that description segment is our objective variable must be highlighted where NLP activities are performed on it and after that vectorized by utilizing TFIDF. 

* From that point forward, all that was left was to track down the clusters and fit our models by knowing various clusters, and further, the model is assessed utilizing the metrics.



![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)


<h2> :book: Dataset information:</h2>


* Show id: Unique ID for every Movie / Tv Show


* type – Identifier - A Movie or TV Show


* title – Title of the Movie / Tv Show


* director-director of the content


* cast –Actors involved in the movie / show


* country – Country where the movie / show was produced


* date added – Date it was added on Netflix


* release year – Actual Release year of the movie / show


* rating – TV Rating of the movie / show


* duration – Total Duration - in minutes or number of seasons


* listed in – genre 


* description – The Summary description



![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

<h2> :book: Problem Statement:</h2>

* This dataset consists of TV shows and movies available on Netflix as of 2019. 

* The dataset is collected from Flexible which is a third-party Netflix search engine

* In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010.

* The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. 

* It will be interesting to explore what all other insights can be obtained from the same dataset.

* Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings.



![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

<h2> :book: Conclusion:</h2>

* Our main goal in this project was to determine different clusters based on content, which we have done.

* After using the Silhouette score and the elbow method, we found that 28 clusters would be suitable.

* which we evaluated using the Davies-Bouldin index and the Calinski-Harabasz score.

* Our clusters were homogeneous within clusters and heterogeneous with respect to other clusters.



![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)

* Ppt Presentation Link:-https://drive.google.com/file/d/1jvRgL4MaxtfirqGdBOTdmA62WMWgyWRS/view?usp=sharing




![-----------------------------------------------------](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png)
